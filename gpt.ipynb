{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT : from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dataset in characters: 1115394\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print('length of the dataset in characters:',len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting all the unique characters in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing (Building Encoder & Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]  #input string ---> output list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "print(encode('hii there'))\n",
    "print(decode(encode('hii there')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the dataset and stroing into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader : batch of chunks of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block size or context size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1] #because input and lable 8 will be input and last one is output(targets) of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'when input is {context} the target: {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Dimension : chunks of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel\n",
    "block_size = 8 # maximum context length for predictions\n",
    "\n",
    "\n",
    "#creating 4 batches\n",
    "def get_batch(split):\n",
    "    #generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split=='train' else val_data\n",
    "\n",
    "    ix = torch.randint(len(data)-block_size,(batch_size,))\n",
    "\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "\n",
      "\n",
      "targets\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "#getting x batch xb, y batch yb\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('targets')\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Batch---\n",
      "when input is tensor([24]) target is: 43\n",
      "when input is tensor([24, 43]) target is: 58\n",
      "when input is tensor([24, 43, 58]) target is: 5\n",
      "when input is tensor([24, 43, 58,  5]) target is: 57\n",
      "when input is tensor([24, 43, 58,  5, 57]) target is: 1\n",
      "when input is tensor([24, 43, 58,  5, 57,  1]) target is: 46\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46]) target is: 43\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) target is: 39\n",
      "____\n",
      "\n",
      "---Batch---\n",
      "when input is tensor([44]) target is: 53\n",
      "when input is tensor([44, 53]) target is: 56\n",
      "when input is tensor([44, 53, 56]) target is: 1\n",
      "when input is tensor([44, 53, 56,  1]) target is: 58\n",
      "when input is tensor([44, 53, 56,  1, 58]) target is: 46\n",
      "when input is tensor([44, 53, 56,  1, 58, 46]) target is: 39\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39]) target is: 58\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) target is: 1\n",
      "____\n",
      "\n",
      "---Batch---\n",
      "when input is tensor([52]) target is: 58\n",
      "when input is tensor([52, 58]) target is: 1\n",
      "when input is tensor([52, 58,  1]) target is: 58\n",
      "when input is tensor([52, 58,  1, 58]) target is: 46\n",
      "when input is tensor([52, 58,  1, 58, 46]) target is: 39\n",
      "when input is tensor([52, 58,  1, 58, 46, 39]) target is: 58\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58]) target is: 1\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) target is: 46\n",
      "____\n",
      "\n",
      "---Batch---\n",
      "when input is tensor([25]) target is: 17\n",
      "when input is tensor([25, 17]) target is: 27\n",
      "when input is tensor([25, 17, 27]) target is: 10\n",
      "when input is tensor([25, 17, 27, 10]) target is: 0\n",
      "when input is tensor([25, 17, 27, 10,  0]) target is: 21\n",
      "when input is tensor([25, 17, 27, 10,  0, 21]) target is: 1\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1]) target is: 54\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) target is: 39\n",
      "____\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size): #batch dimension\n",
    "    print('---Batch---')\n",
    "    for t in range(block_size): #time dimension or context size\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'when input is {context} target is: {target}')\n",
    "    print('____\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biagram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating a token embedding table of vocab_size * vocab_size i.e 65*65 \\n \n",
    "idx will go to this emebdding table and pluck out the row of size 65 for example here\n",
    "24 will to go the embedding table and pluck out the 24th row.\n",
    "\n",
    "Pytorch arrange these tensors in B,T,C dimensions\n",
    "\n",
    "where \n",
    "\n",
    "      Batch size (B) = 4\n",
    "\n",
    "      Time(context) T = 8\n",
    "\n",
    "      channels(vocab size) c = 65\n",
    "\n",
    "here tokens are not talking to each other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BiagramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        #each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "\n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(B,T,C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "        #reshaping the logits inot B,C,T which suitable for cross entropy loss\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "        return logits,loss\n",
    "    \n",
    "    #generate function for the model\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idc is (B,T) array of indices in the current context\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the predictions\n",
    "            logits,loss = self(idx) #which calls forward method\n",
    "\n",
    "            #focus only on the last time step\n",
    "            logits = logits[:,-1,:]  # becomes B,C\n",
    "\n",
    "            #apply softmax to get probabilites\n",
    "            probs = F.softmax(logits,dim=-1) # B,C\n",
    "\n",
    "            #sample from distribution\n",
    "            idx_next = torch.multinomial(probs,num_samples=1) #(B,1)\n",
    "\n",
    "            #append sampled index to the running sequence\n",
    "            idx = torch.cat((idx,idx_next),dim=-1)  # (B,T+1)\n",
    "        return idx\n",
    "m = BiagramLanguageModel(vocab_size)\n",
    "logits,loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "generated_output = m.generate(idx = idx,max_new_tokens=100)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 31, 23, 21, 41, 24, 32, 11, 13, 41, 17, 24, 25, 53, 32, 40, 60, 38, 60, 1, 15, 12, 52, 55, 7, 29, 17, 9, 9, 10, 15, 22, 55, 49, 27, 23, 20, 7, 55, 11, 10, 50, 39, 2, 53, 47, 63, 61, 49, 20, 48, 45, 15, 46, 64, 40, 29, 12, 59, 2, 9, 40, 24, 21, 45, 61, 43, 60, 51, 63, 18, 22, 19, 33, 19, 54, 0, 61, 52, 37, 35, 51, 52, 62, 23, 35, 35, 43, 60, 7, 58, 16, 55, 36, 17, 56, 34, 23, 24, 45, 22]\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "print(generated_output)\n",
    "print(decode(generated_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishna/anaconda3/envs/ai_text/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#create a pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.684566974639893\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(10000):\n",
    "\n",
    "    #sample batch of data\n",
    "    xb,yb = get_batch('train')\n",
    "\n",
    "    #evalate the loss\n",
    "    logits,loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pgu3KpoiPFhix\n",
      "SJ'\n",
      "yFjjN3Q&u3WgMmywW$GJL?sPY?YtNpErgIo,XcJ&DniqVmZBwfFD3faBoi'I3Q?$xBr&G,yxUN!Wsyy cLC-IBothTsze'W?q;!:xrFti.ZQyJyQ!u!zHK$EQq-wM.T'QUiN.SPyjKtL&vbRwW,SZBCj?aUIUxDALpAUGFbLQXNVY.sBId-'wNm;UL:3Sq-KAiqRiN:lL-Qm,iCulyZUAP,oSB3SlriFWiy;GJ,NuUxxTER-!a!UYN\n",
      "kOpJU'usc UIo.JAa!U CjuRw'TthF;aLq-KX&jzCE;HzE-Wla!uDKBjuxVBk!UQXlFlaXt,wWWV&G;HU?zW:.ObX?wfRkRyJBUzK$Evi\n",
      "hjdlgGrT?I33StKa;AUGJAE-WWgI'VPwKoQ3TqSt:BAE3sttTER&ZTOMmR:Ckzr$zL&d&AUy IXROZPn;ERq,s$:C ,jKtxHCFT;yVajH:i3SPjuCPOJXSPNuHW:r:dcxZph'Q&ZgIQ3xEaj,pN3:CKpJgmOvUAURpgId, -bGlvmUiWW.Db:zPyIlfpepuMkgDuC!\n",
      "SGXyXH;?ovnpO z:qDQqQEN.C&f WMp'bkqhX.NgA Cjue;Jr&uktXC pUt3QyCuiMyCj?n;3ct CKfBktIBL'IE$gCJdVzP!Kus fq-bW,GlgMsrVhSsuli'PgnNL;RwbvvN.?wfIPkSyjnpmZAUEJyGGNLE3pGJGoi:'Dnq,c;:bj?:CJKOv:C b?phEJ?up$epYppYNWmhhf.sC&yIiASh\n",
      "AcMa\n",
      "SP$PgxlnoiAWttib?n;AH,L;;hskpD.D!o'IVj;hMGZS-gkJrIF.SPi-iv' &D.\n",
      "gdcLfjAcBotphWWERiyNW\n",
      "oCgFA?RGMlv?OTFlDqdTWv.\n",
      "ISqgSlIV;VRlylvviO'jQJJFbsEy;AfIcP p fdz&LEQJObkq-3SBTh;PgQbDC,SGTqttxKAcIKBTAcmNu!C-WxEsLtqRp3SU\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "generated_output = m.generate(idx = idx,max_new_tokens=1000)[0].tolist()\n",
    "print(decode(generated_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

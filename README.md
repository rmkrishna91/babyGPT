# 🍼 babyGPT

A tiny GPT model built from scratch, inspired by Andrej Karpathy's "Let's build GPT" YouTube series.

This is a **work-in-progress** project where I'm learning how to build a transformer-based language model (like GPT) from the ground up using PyTorch. I'm following along with Karpathy’s tutorials and updating this repo as I go — one step at a time.

---

## 🚧 Current Status

✅ Repo created  
✅ Started coding along with the notebook  
🔜 Next: Finish tokenizer, model blocks, and training loop

I’m working on this daily in small chunks, so stay tuned!

---

## 📁 Files So Far

- `babygpt.ipynb` – Main notebook where I'm writing and testing code
- `babygpt.py` – Script version (currently being updated as I go)
- `requirements.txt` – Basic dependencies

---

## 🧠 Tech Stack

- Python
- PyTorch
- Jupyter Notebook

